{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "487ca195",
   "metadata": {},
   "source": [
    "1. Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03dff01",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 22:44:47.553141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os as os\n",
    "import numpy as np\n",
    "import xlrd as xlrd\n",
    "import bertopic\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "# bigram 생성에 필요한 library\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "# vectorize & lda에 필요한 library\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import re\n",
    "import string \n",
    "string.punctuation\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13bcb37b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "base_path = '/Users/gansujin/Documents/research/2024/homehealthcare/2024/preprocessing'\n",
    "record_path = os.path.join(base_path, 'tokens.xlsx')\n",
    "record = pd.read_excel(record_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1471fb28",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "note = pd.DataFrame(record, columns = ['person_id','note_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45bfcfc1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "note = note.reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bcb0dd5",
   "metadata": {},
   "source": [
    "Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9cf47dc",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "tokens = pd.DataFrame(note, columns = ['person_id','note_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "238b657b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "tokens = tokens.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49d63db2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# stopwords for department \n",
    "\n",
    "unitwords = ['pgdl','ngml','cm','pgml','ul','lmin','mgdl','mmoll','mmhg','x㎕', 'pak','cc','inch','rt','lt','side','cc','rd',\n",
    "               'gdl','wbc','ugl','mg','g','mgml','kg','ml', 'tab','cap', '×μl', 'medication', 'wks','opd',\n",
    "               'days', 'xμl', 'mlpak', 'phx','fhx', '×μl', 'identification','cheif problem','phx and fhx']\n",
    "specialty_en = ['pimd', 'gimd', 'edmd','nemd','hemd','onmd','almd','opth','indm', 'ermd','cpat']\n",
    "specialty_kor = ['가정의학','감염내','갑상선내분비외','급성기일반내','내분비대사내','간이식및간담도외','정신과',\n",
    "                '대장항문외','류마티스내','마취통증의학','방사선종양학','비뇨의학','산부인','비뇨기과','cc','시','ent','homd','edmd','nemd',\n",
    "                '성형외','소아','소아청소년','소화기내','순환기내','신경','신경외','신장내','안과','소아외과','알레르기내','영상의학','외상외','위장관외','유방외','응급의학','응급중환자외','이비인후','내분비내과',\n",
    "               '이식혈관외','재활의학','정신건강의학','정형외','종양혈액내','직업환경의학','진단검사의학','취담도외','핵의학','호흡기내','흉부외','가정의학과','감염내과','갑상선내분비외과','급성기일반내과',\n",
    "               '내분비대사내과','간이식및간담도외과','대장항문외과','류마티스내과','마취통증의학과','방사선종양학과','병리과','비뇨의학과','산부인과','성형외과','소아과','소아청소년과','소화기내과','순환기내과','신경과','췌담도외과',\n",
    "                 '신경외과','신장내과','안과','알레르기내과','영상의학과','외상외과','위장관외과','유방외과','유방암센터','외래','종양혈액내과','월일','유방외과','신장내과',\n",
    "                '응급의학과','응급중환자외과','이비인후과','이식혈관외과','재활의학과','정신건강의학과','정형외과','혈액종양내과','종양혈액','내과','내원시','본원','종양혈액내과','직업환경의학과','진단검사의학과','취담도외과','핵의학과','호흡기내과','흉부외과','정신의학과']\n",
    "\n",
    "mystopwords = unitwords + specialty_en + specialty_kor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd56c28d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    tokens = text.split(' ')\n",
    "    meaningful = [w for w in tokens if not w in mystopwords]\n",
    "    return ' '.join(meaningful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30dbd7f0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the remove_stopwords function to all columns\n",
    "note = note.applymap(lambda x: remove_stopwords(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6e8ecd2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    splits = text.split( )\n",
    "    words = []\n",
    "    for word in splits:\n",
    "        if word not in mystopwords:\n",
    "            words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "134a1fb0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_list = []\n",
    "\n",
    "for text in note['note_text']:\n",
    "    tokenized_list.append(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6022530a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "token_df = pd.DataFrame(tokenized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1871b6a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "token_df['text'] = token_df.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51f45dd0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Replace multiple spaces with a single space\n",
    "token_df['text'] = token_df['text'].replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8582d92",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Your code to tokenize and filter\n",
    "tokenized_list = []\n",
    "drop_mask = []\n",
    "\n",
    "for text in token_df['text']:\n",
    "    tokenized = tokenize(text)\n",
    "    if len(set(tokenized)) < 3:\n",
    "        drop_mask.append(True)\n",
    "    else:\n",
    "        drop_mask.append(False)\n",
    "    tokenized_list.append(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7353f4c8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame without rows where drop_mask is True\n",
    "filtered_df = token_df[~pd.Series(drop_mask)]\n",
    "\n",
    "# Reset the index while keeping the original index in a separate column\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "filtered_df['original_index'] = token_df[~pd.Series(drop_mask)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8acb26d8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "filtered_list = []\n",
    "\n",
    "for text in filtered_df['text']:\n",
    "    filtered_list.append(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ceec6ff5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "clean = [tkn for tkn in filtered_list if not any(stop in tkn for stop in mystopwords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49d10492",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b43751d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "clean_df['note_text'] = clean_df.iloc[:, 0:37].fillna('').apply(lambda x: ' '.join(x.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5357dbc1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "clean_df.sentence = clean_df.apply(lambda row: re.sub(\" ,\", \" \", row.note_text).lower(), 1) # 문장형태로 바뀐 문장들을 sentence 열에 할당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c8811a16",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sentence_list = clean_df.sentence.to_list() # 토픽모델링을 진행하기 전에, sentence열을 list 타입으로 바꾸어 sentence_list에 할당합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "225c4b06",
   "metadata": {},
   "source": [
    "Bertopic development flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "1c74b5e4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1 - Extract embeddings\n",
    "sentence_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "embeddings = sentence_model.encode(sentence_list, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "99f821ff",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors= 5, min_dist=0.05, n_components=5, random_state=42, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "96f72a4a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "hdbscan_model = HDBSCAN(min_cluster_size = 10, metric = 'euclidean', cluster_selection_method='eom', prediction_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "37dc9628",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "representation_model = MaximalMarginalRelevance(diversity = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "db70b744",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ctfidf_model = ClassTfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4576df52",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer = tokenize, ngram_range=(1,2), stop_words = mystopwords\n",
    "                        ,max_df = 0.9 # 90% 이상 등장하는 단어 제외\n",
    "                        ,min_df = 2 # 1회 등장하는 단어 제외 \n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0d46a544",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "topic_model = BERTopic(language = 'korean', umap_model=umap_model, embedding_model=sentence_model, verbose = True, representation_model = representation_model,\n",
    "                          hdbscan_model = hdbscan_model, vectorizer_model = vectorizer, ctfidf_model = ctfidf_model, \n",
    "                          calculate_probabilities=True, min_topic_size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b9c5ed58",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 22:21:03,399 - BERTopic - Reduced dimensionality\n",
      "2024-01-12 22:21:03,596 - BERTopic - Clustered reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(sentence_list, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "045b6f6b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "topic_labels = topic_model.generate_topic_labels(nr_words = 30, separator= \", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c1a72",
   "metadata": {},
   "source": [
    "Optimal topic numbers\n",
    "\n",
    "silhouette_scores = []; 1에 가까울 수록 좋다. A good silhouette score is close to 1, and it suggests that the data points within a cluster are similar to each other and dissimilar to points in other clusters.\n",
    "davies_bouldin_scores = []; 0에 가까울 수록 좋다. The Davies-Bouldin index measures the compactness and separation between clusters. A lower Davies-Bouldin index indicates better clustering.\n",
    "It is the average similarity ratio of each cluster with its most similar cluster. Lower values are desirable, and 0 indicates perfectly separated clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0edf9",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "num_topics_list = range(1,50)\n",
    "silhouette_scores = []\n",
    "davies_bouldin_scores = []\n",
    "best_num_topics = None\n",
    "best_silhouette_score = -1\n",
    "best_davies_bouldin_index = float('inf')\n",
    "\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "sentence_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "embeddings = sentence_model.encode(sentence_list, show_progress_bar=False)\n",
    "\n",
    "# Iterate over different numbers of topics\n",
    "for num_topics in num_topics_list:\n",
    "    # Train the topic model\n",
    "    topic_model = BERTopic(\n",
    "        language = 'korean', umap_model=umap_model, embedding_model=sentence_model, verbose = True, representation_model = representation_model,\n",
    "                          hdbscan_model = hdbscan_model, vectorizer_model = vectorizer, ctfidf_model = ctfidf_model, \n",
    "                          calculate_probabilities=True, min_topic_size = 5, nr_topics=num_topics)\n",
    "\n",
    "\n",
    "    # Generate `X` and `labels` only for non-outlier topics (as they are technically not clusters)\n",
    "    umap_embeddings = topic_model.umap_model.transform(embeddings)\n",
    "    indices = [index for index, topic in enumerate(topics) if topic != -1]\n",
    "    X = umap_embeddings[np.array(indices)]\n",
    "    labels = [topic for index, topic in enumerate(topics) if topic != -1]\n",
    "\n",
    "\n",
    "    # Calculate silhouette score \n",
    "    silhouette = silhouette_score(X, labels)\n",
    "    silhouette_scores.append(silhouette)\n",
    "\n",
    "    # Calculate Davies-Bouldin score\n",
    "    davies_bouldin = davies_bouldin_score(X, labels)\n",
    "    davies_bouldin_scores.append(davies_bouldin)\n",
    "\n",
    "    # Update best scores and number of topics\n",
    "    if silhouette > best_silhouette_score:\n",
    "        best_silhouette_score = silhouette\n",
    "        best_davies_bouldin_index = davies_bouldin\n",
    "        best_num_topics = num_topics\n",
    "\n",
    "# Print the best number of topics and corresponding scores\n",
    "print(\"Best Number of Topics:\", best_num_topics)\n",
    "print(\"Best Silhouette Score:\", best_silhouette_score)\n",
    "print(\"Best Davies-Bouldin Index:\", best_davies_bouldin_index)\n",
    "# Plotting\n",
    "plt.plot(num_topics_list, silhouette_scores, label='Silhouette Score')\n",
    "plt.plot(num_topics_list, davies_bouldin_scores, label='Davies-Bouldin Score')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Topic Modeling Evaluation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c860a83a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "original_document = topic_model.get_document_info(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "22290056",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "original_document =  pd.concat([original_document, pd.DataFrame(probs)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d775d0",
   "metadata": {},
   "source": [
    "Outlier reduction\n",
    ": -1 (outlier topic) 에 속해서 prob 값 0 가졌던 document 에 다른 토픽 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "59a1bf57",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "new_topics = topic_model.reduce_outliers(sentence_list, topics, probabilities=probs, strategy=\"probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "98990460",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "topic_model.update_topics(sentence_list, topics=new_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "00d0512a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "topic_labels = topic_model.generate_topic_labels(nr_words = 30, separator=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "fbb7711e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "document_info = topic_model.get_document_info(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "11bae80f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "document_info =  pd.concat([document_info, pd.DataFrame(probs)], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0af7b63c",
   "metadata": {},
   "source": [
    "Merge probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "dd65dabe",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Define the column to exclude from the sum\n",
    "column_to_exclude = 'Document'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "4875e8cd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting specific columns\n",
    "Topic1 = document_info[['Document',0,2,11,14,17,18,24]] #post operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "6a494abf",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Topic1['Topic1'] = Topic1.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f23486dd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting specific columns\n",
    "Topic2 = document_info[['Document', 1, 10,22,23,26,27]] #Nutrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "4a5192e4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Topic2['Topic2'] = Topic2.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3c20cb89",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting specific columns\n",
    "Topic3 = document_info[['Document', 3,4,7,12,13,15,16,25,30]] #adl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "3b76c9a8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Topic3['Topic3'] = Topic3.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "efb34690",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Topic4 = document_info[['Document', 5, 6,8,9,20,28,29]] #mental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "53962394",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Topic4['Topic4'] = Topic4.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "84ef1fe3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Topic5 = document_info[['Document', 19,21,31]] #dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "c433dfdb",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "Topic5['Topic5'] = Topic5.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "1e925542",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate the dataframes along their columns (c-bind)\n",
    "result_df = pd.concat([Topic1, Topic2, Topic3, Topic4, Topic5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "71fc72fb",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "result_df = result_df[['Document','Topic1','Topic2','Topic3','Topic4','Topic5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "74505489",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "result = result_df.iloc[:,5:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "6c363693",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "result.to_excel('result.xlsx', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
